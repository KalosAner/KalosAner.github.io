---
layout:       post
title:        "联邦学习之联邦LLM微调"
author:       "kalos Aner"
header-style: text
catalog:      true
tags:
    

---

### 联邦微调系列



### 引言

LLM 是非常强大的工具，但是它的训练却受到场景的限制。

考虑在一个多个地区的医院里使用医疗数据来训练 LLM，由于医疗数据都是隐私数据，所以不能把数据传输到服务器进行训练，这时就需要用到联邦 LLM 微调。

在进行联邦 LLM 微调时有两点需要注意：

第一点：不要试图从头开始训练 LLM，而是使用预训练模型，并使用私有数据进行微调。

第二点：进一步优化标准的微调方法，采用参数高效微调（Parameter-Efficient Fine-Tuning，PEFT）。在微调过程中，PEFT 只需要修改 LLM 权重的一小部分，而不是更新所有参数。

由于有通过 LLM 来恢复训练数据的风险，在使用微调时还需要加入差分隐私等隐私技术。
